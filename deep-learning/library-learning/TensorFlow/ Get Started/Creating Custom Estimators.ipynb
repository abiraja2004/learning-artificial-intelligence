{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Custom Estimators\n",
    "\n",
    "This document introduces custom Estimators. In particular, this document demonstrates how to create a custom [Estimator](https://tensorflow.google.cn/api_docs/python/tf/estimator/Estimator) that mimics the behavior of the pre-made Estimator [DNNClassifier](https://tensorflow.google.cn/api_docs/python/tf/estimator/DNNClassifier) in solving the Iris problem. See the [Pre-Made Estimators chapter](https://tensorflow.google.cn/get_started/premade_estimators) for details on the Iris problem.\n",
    "\n",
    "## Pre-made vs. custom\n",
    "\n",
    "As the following figure shows, pre-made Estimators are subclasses of the tf.estimator.Estimator base class, while custom Estimators are an instance of tf.estimator.Estimator:\n",
    "\n",
    "![](https://tensorflow.google.cn/images/custom_estimators/estimator_types.png)\n",
    "<center>Pre-made and custom Estimators are all Estimators.</center>\n",
    "\n",
    "Pre-made Estimators are fully baked. Sometimes though, you need more control over an Estimator's behavior. That's where custom Estimators come in. You can create a custom Estimator to do just about anything. If you want hidden layers connected in some unusual fashion, write a custom Estimator. If you want to calculate a unique metric for your model, write a custom Estimator. Basically, if you want an Estimator optimized for your specific problem, write a custom Estimator.\n",
    "\n",
    "A model function (or model_fn) implements the ML algorithm. The only difference between working with pre-made Estimators and custom Estimators is:\n",
    "\n",
    "- With pre-made Estimators, someone already wrote the model function for you.\n",
    "- With custom Estimators, you must write the model function.\n",
    "\n",
    "Your model function could implement a wide range of algorithms, defining all sorts of hidden layers and metrics. Like input functions, all model functions must accept a standard group of input parameters and return a standard group of output values. Just as input functions can leverage the Dataset API, model functions can leverage the Layers API and the Metrics API.\n",
    "\n",
    "Let's see how to solve the Iris problem with a custom Estimator. A quick reminder--here's the organization of the Iris model that we're trying to mimic:\n",
    "\n",
    "A diagram of the network architecture: Inputs, 2 hidden layers, and outputs\n",
    "\n",
    "![](https://tensorflow.google.cn/images/custom_estimators/full_network.png)\n",
    "<center>Our implementation of Iris contains four features, two hidden layers, and a logits output layer.</center>\n",
    "\n",
    "## Write an Input function\n",
    "Our custom Estimator implementation uses the same input function as our [pre-made Estimator implementation](https://tensorflow.google.cn/get_started/premade_estimators), from iris_data.py. Namely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the read end of the pipeline.\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This input function builds an input pipeline that yields batches of (features, labels) pairs, where features is a dictionary features.\n",
    "\n",
    "## Create feature columns\n",
    "\n",
    "As detailed in the Premade Estimators and Feature Columns chapters, you must define your model's feature columns to specify how the model should use each feature. Whether working with pre-made Estimators or custom Estimators, you define feature columns in the same fashion.\n",
    "\n",
    "The following code creates a simple numeric_column for each input feature, indicating that the value of the input feature should be used directly as an input to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import iris_data\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = iris_data.load_data()\n",
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a model function\n",
    "\n",
    "The model function we'll use has the following call signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(\n",
    "    features, # This is batch_features from input_fn\n",
    "    labels,   # This is batch_labels from input_fn\n",
    "    mode,     # An instance of tf.estimator.ModeKeys\n",
    "    params):  # Additional configuration\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two arguments are the batches of features and labels returned from the input function; that is, features and labels are the handles to the data your model will use. The mode argument indicates whether the caller is requesting training, predicting, or evaluation.\n",
    "\n",
    "The caller may pass params to an Estimator's constructor. Any params passed to the constructor are in turn passed on to the model_fn. In [custom_estimator.py](https://github.com/tensorflow/models/blob/master/samples/core/get_started/custom_estimator.py) the following lines create the estimator and set the params to configure the model. This configuration step is similar to how we configured the [tf.estimator.DNNClassifier](https://tensorflow.google.cn/api_docs/python/tf/estimator/DNNClassifier) in [Premade Estimators](https://tensorflow.google.cn/get_started/premade_estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmp5zvsgx9v\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmp5zvsgx9v', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023AA28DA4A8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=my_model,\n",
    "    params={\n",
    "        'feature_columns': my_feature_columns,\n",
    "        # Two hidden layers of 10 nodes each.\n",
    "        'hidden_units': [10, 10],\n",
    "        # The model must choose between 3 classes.\n",
    "        'n_classes': 3,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement a typical model function, you must do the following:\n",
    "\n",
    "- [Define the model](https://tensorflow.google.cn/get_started/custom_estimators#define_the_model).\n",
    "- Specify additional calculations for each of the [three different modes](https://tensorflow.google.cn/get_started/custom_estimators#modes):\n",
    "    - [Predict](https://tensorflow.google.cn/get_started/custom_estimators#predict)\n",
    "    - [Evaluate](https://tensorflow.google.cn/get_started/custom_estimators#evaluate)\n",
    "    - [Train](https://tensorflow.google.cn/get_started/custom_estimators#train)\n",
    "    \n",
    "## Define the model\n",
    "\n",
    "The basic deep neural network model must define the following three sections:\n",
    "\n",
    "- An [input layer](https://developers.google.cn/machine-learning/glossary/#input_layer)\n",
    "- One or more [hidden layers](https://developers.google.cn/machine-learning/glossary/#hidden_layer)\n",
    "- An [output layer](https://developers.google.cn/machine-learning/glossary/#hidden_layer)\n",
    "\n",
    "### Define the input layer\n",
    "The first line of the model_fn calls [tf.feature_column.input_layer](https://tensorflow.google.cn/api_docs/python/tf/feature_column/input_layer) to convert the feature dictionary and feature_columns into input for your model, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use `input_layer` to apply the feature columns.\n",
    "net = tf.feature_column.input_layer(features, params['feature_columns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding line applies the transformations defined by your feature columns, creating the model's input layer.\n",
    "\n",
    "![](https://tensorflow.google.cn/images/custom_estimators/input_layer.png)\n",
    "\n",
    "### Hidden Layers\n",
    "If you are creating a deep neural network, you must define one or more hidden layers. The Layers API provides a rich set of functions to define all types of hidden layers, including convolutional, pooling, and dropout layers. For Iris, we're simply going to call [tf.layers.dense](https://tensorflow.google.cn/api_docs/python/tf/layers/dense) to create hidden layers, with dimensions defined by params['hidden_layers']. In a dense layer each node is connected to every node in the preceding layer. Here's the relevant code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the hidden layers, sized according to the 'hidden_units' param.\n",
    "for units in params['hidden_units']:\n",
    "    net = tf.layers.dense(net, units=units, activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The units parameter defines the number of output neurons in a given layer.\n",
    "- The activation parameter defines the [activation function](https://developers.google.cn/machine-learning/glossary/#activation_function) — [Relu](https://developers.google.cn/machine-learning/glossary/#ReLU) in this case.\n",
    "\n",
    "The variable net here signifies the current top layer of the network. During the first iteration, net signifies the input layer. On each loop iteration [tf.layers.dense](https://tensorflow.google.cn/api_docs/python/tf/layers/dense) creates a new layer, which takes the previous layer's output as its input, using the variable net.\n",
    "\n",
    "After creating two hidden layers, our network looks as follows. For simplicity, the figure does not show all the units in each layer.\n",
    "\n",
    "![](https://tensorflow.google.cn/images/custom_estimators/add_hidden_layer.png)\n",
    "\n",
    "Note that [tf.layers.dense](https://tensorflow.google.cn/api_docs/python/tf/layers/dense) provides many additional capabilities, including the ability to set a multitude of regularization parameters. For the sake of simplicity, though, we're going to simply accept the default values of the other parameters.\n",
    "\n",
    "### Output Layer\n",
    "We'll define the output layer by calling tf.layers.dense yet again, this time without an activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute logits (1 per class).\n",
    "logits = tf.layers.dense(net, params['n_classes', activation=None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, net signifies the final hidden layer. Therefore, the full set of layers is now connected as follows:\n",
    "\n",
    "![](https://tensorflow.google.cn/images/custom_estimators/add_logits.png)\n",
    "<center>The final hidden layer feeds into the output layer.</center>\n",
    "\n",
    "When defining an output layer, the units parameter specifies the number of outputs. So, by setting units to params['n_classes'], the model produces one output value per class. Each element of the output vector will contain the score, or \"logit\", calculated for the associated class of Iris: Setosa, Versicolor, or Virginica, respectively.\n",
    "\n",
    "Later on, these logits will be transformed into probabilities by the [tf.nn.softmax](https://tensorflow.google.cn/api_docs/python/tf/nn/softmax) function.\n",
    "\n",
    "## Implement training, evaluation, and prediction\n",
    "The final step in creating a model function is to write branching code that implements prediction, evaluation, and training.\n",
    "\n",
    "The model function gets invoked whenever someone calls the Estimator's train, evaluate, or predict methods. Recall that the signature for the model function looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_model_fn(\n",
    "   features, # This is batch_features from input_fn\n",
    "   labels,   # This is batch_labels from input_fn\n",
    "   mode,     # An instance of tf.estimator.ModeKeys, see below\n",
    "   params):  # Additional configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus on that third argument, mode. As the following table shows, when someone calls train, evaluate, or predict, the Estimator framework invokes your model function with the mode parameter set as follows:\n",
    "\n",
    "| Estimator method | Estimator Mode   |\n",
    "| ---------------- | ---------------- |\n",
    "| [train()](https://tensorflow.google.cn/api_docs/python/tf/estimator/BaselineClassifier#train)          | [ModeKeys.TRAIN](https://tensorflow.google.cn/api_docs/python/tf/estimator/ModeKeys#TRAIN)   |\n",
    "| [evaluate()](https://tensorflow.google.cn/api_docs/python/tf/estimator/BaselineClassifier#evaluate)       | [ModeKeys.EVAL](https://tensorflow.google.cn/api_docs/python/tf/estimator/ModeKeys#EVAL)    |\n",
    "| [predict()](https://tensorflow.google.cn/api_docs/python/tf/estimator/BaselineClassifier#predict)        | [ModeKeys.PREDICT](https://tensorflow.google.cn/api_docs/python/tf/estimator/ModeKeys#PREDICT) |\n",
    "\n",
    "For example, suppose you instantiate a custom Estimator to generate an object named classifier. Then, you make the following call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = tf.estimator.Estimator(...)\n",
    "classifier.train(input_fn=lambda: my_input_fn(FILE_TRAIN, True, 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Estimator framework then calls your model function with mode set to ModeKeys.TRAIN.\n",
    "\n",
    "Your model function must provide code to handle all three of the mode values. For each mode value, your code must return an instance of [tf.estimator.EstimatorSpec](https://tensorflow.google.cn/api_docs/python/tf/estimator/EstimatorSpec), which contains the information the caller requires. Let's examine each mode.\n",
    "\n",
    "### Predict\n",
    "When the Estimator's predict method is called, the model_fn receives mode = ModeKeys.PREDICT. In this case, the model function must return a [tf.estimator.EstimatorSpec](https://tensorflow.google.cn/api_docs/python/tf/estimator/EstimatorSpec) containing the prediction.\n",
    "\n",
    "The model must have been trained prior to making a prediction. The trained model is stored on disk in the model_dir directory established when you instantiated the Estimator.\n",
    "\n",
    "The code to generate the prediction for this model looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions.\n",
    "predicted_classes = tf.argmax(logits, 1)\n",
    "if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    predictions = {\n",
    "        'class_ids': predicted_classes[:, tf.newaxis],\n",
    "        'probabilities': tf.nn.softmax(logits),\n",
    "        'logits': logits,\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode, predictions=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction dictionary contains everything that your model returns when run in prediction mode.\n",
    "\n",
    "![](https://tensorflow.google.cn/images/custom_estimators/add_predictions.png)\n",
    "\n",
    "The predictions holds the following three key/value pairs:\n",
    "\n",
    "- class_ids holds the class id (0, 1, or 2) representing the model's prediction of the most likely species for this example.\n",
    "- probabilities holds the three probabilities (in this example, 0.02, 0.95, and 0.03)\n",
    "- logit holds the raw logit values (in this example, -1.3, 2.6, and -0.9)\n",
    "\n",
    "We return that dictionary to the caller via the predictions parameter of the [tf.estimator.EstimatorSpec](https://tensorflow.google.cn/api_docs/python/tf/estimator/EstimatorSpec). The Estimator's [predict](https://tensorflow.google.cn/api_docs/python/tf/estimator/BaselineClassifier#predict) method will yield these dictionaries.\n",
    "\n",
    "### Calculate the loss\n",
    "For both [training](https://tensorflow.google.cn/get_started/custom_estimators#train) and [evaluation](https://tensorflow.google.cn/get_started/custom_estimators#evaluate) we need to calculate the model's loss. This is the [objective](https://developers.google.cn/machine-learning/glossary/#objective) that will be optimized.\n",
    "\n",
    "We can calculate the loss by calling [tf.losses.sparse_softmax_cross_entropy](https://tensorflow.google.cn/api_docs/python/tf/losses/sparse_softmax_cross_entropy). The value returned by this function will be lowest, approximately 0, probability of the correct class (at index label) is near 1.0. The loss value returned is progressively larger as the probability of the correct class decreases.\n",
    "\n",
    "This function returns the average over the whole batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loss.\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "When the Estimator's evaluate method is called, the model_fn receives mode = ModeKeys.EVAL. In this case, the model function must return a [tf.estimator.EstimatorSpec](https://tensorflow.google.cn/api_docs/python/tf/estimator/EstimatorSpec) containing the model's loss and optionally one or more metrics.\n",
    "\n",
    "Although returning metrics is optional, most custom Estimators do return at least one metric. TensorFlow provides a Metrics module [tf.metrics](https://tensorflow.google.cn/api_docs/python/tf/metrics) to calculate common metrics. For brevity's sake, we'll only return accuracy. The [tf.metrics.accuracy](https://tensorflow.google.cn/api_docs/python/tf/metrics/accuracy) function compares our predictions against the true values, that is, against the labels provided by the input function. The [tf.metrics.accuracy](https://tensorflow.google.cn/api_docs/python/tf/metrics/accuracy) function requires the labels and predictions to have the same shape. Here's the call to [tf.metrics.accuracy](https://tensorflow.google.cn/api_docs/python/tf/metrics/accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics.\n",
    "accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                                  predictions=predicted_classes,\n",
    "                                                  name='acc_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [EstimatorSpec](https://tensorflow.google.cn/api_docs/python/tf/estimator/EstimatorSpec) returned for evaluation typically contains the following information:\n",
    "\n",
    "- loss, which is the model's loss\n",
    "- eval_metric_ops, which is an optional dictionary of metrics.\n",
    "\n",
    "So, we'll create a dictionary containing our sole metric. If we had calculated other metrics, we would have added them as additional key/value pairs to that same dictionary. Then, we'll pass that dictionary in the eval_metric_ops argument of [tf.estimator.EstimatorSpec](https://tensorflow.google.cn/api_docs/python/tf/estimator/EstimatorSpec). Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'accuracy': accuracy}\n",
    "tf.summary.scalar('accuracy', accuracy[1])\n",
    "\n",
    "if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode, loss=loss, eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [tf.summary.scalar](https://tensorflow.google.cn/api_docs/python/tf/summary/scalar) will make accuracy available to TensorBoard in both TRAIN and EVAL modes. (More on this later).\n",
    "\n",
    "### Train\n",
    "When the Estimator's train method is called, the model_fn is called with mode = ModeKeys.TRAIN. In this case, the model function must return an EstimatorSpec that contains the loss and a training operation.\n",
    "\n",
    "Building the training operation will require an optimizer. We will use [tf.train.AdagradOptimizer](https://tensorflow.google.cn/api_docs/python/tf/train/AdagradOptimizer) because we're mimicking the DNNClassifier, which also uses Adagrad by default. The [tf.train](https://tensorflow.google.cn/api_docs/python/tf/train) package provides many other optimizers—feel free to experiment with them.\n",
    "\n",
    "Here is the code that builds the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build the training operation using the optimizer's [minimize](https://tensorflow.google.cn/api_docs/python/tf/train/AdadeltaOptimizer#minimize) method on the loss we calculated earlier.\n",
    "\n",
    "The minimize method also takes a global_step parameter. TensorFlow uses this parameter to count the number of training steps that have been processed (to know when to end a training run). Furthermore, the global_step is essential for TensorBoard graphs to work correctly. Simply call [tf.train.get_global_step](https://tensorflow.google.cn/api_docs/python/tf/train/get_global_step) and pass the result to the global_step argument of minimize.\n",
    "\n",
    "Here's the code to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [EstimatorSpec](https://tensorflow.google.cn/api_docs/python/tf/estimator/EstimatorSpec) returned for training must have the following fields set:\n",
    "\n",
    "- loss, which contains the value of the loss function.\n",
    "- train_op, which executes a training step.\n",
    "\n",
    "Here's our code to call EstimatorSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model function is now complete.\n",
    "\n",
    "## The custom Estimator\n",
    "Instantiate the custom Estimator through the Estimator base class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpdsyhch14\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\ADMINI~1\\\\AppData\\\\Local\\\\Temp\\\\tmpdsyhch14', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023AA28DA320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build 2 hidden layer DNN with 10, 10 units respectively.\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=my_model,\n",
    "    params={\n",
    "        'feature_columns': my_feature_columns,\n",
    "        # Two hidden layers of 10 nodes each.\n",
    "        'hidden_units': [10, 10],\n",
    "        # The model must choose between 3 classes.\n",
    "        'n_classes': 3,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the params dictionary serves the same purpose as the key-word arguments of DNNClassifier; that is, the params dictionary lets you configure your Estimator without modifying the code in the model_fn.\n",
    "\n",
    "The rest of the code to train, evaluate, and generate predictions using our Estimator is the same as in the [Premade Estimators](https://tensorflow.google.cn/get_started/premade_estimators) chapter. For example, the following line will train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda:iris_data.train_input_fn(train_x, train_y, args.batch_size),\n",
    "    steps=args.train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard\n",
    "\n",
    "You can view training results for your custom Estimator in TensorBoard. To see this reporting, start TensorBoard from your command line as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace PATH with the actual path passed as model_dir\n",
    "tensorboard --logdir=PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hen, open TensorBoard by browsing to: http://localhost:6006\n",
    "\n",
    "All the pre-made Estimators automatically log a lot of information to TensorBoard. With custom Estimators, however, TensorBoard only provides one default log (a graph of the loss) plus the information you explicitly tell TensorBoard to log. For the custom Estimator you just created, TensorBoard generates the following:\n",
    "\n",
    "![](https://tensorflow.google.cn/images/custom_estimators/accuracy.png)\n",
    "![](https://tensorflow.google.cn/images/custom_estimators/loss.png)\n",
    "![](https://tensorflow.google.cn/images/custom_estimators/steps_per_second.png)\n",
    "<center>TensorBoard displays three graphs.</center>\n",
    "\n",
    "In brief, here's what the three graphs tell you:\n",
    "\n",
    "- global_step/sec: A performance indicator showing how many batches (gradient updates) we processed per second as the model trains.\n",
    "- loss: The loss reported.\n",
    "- accuracy: The accuracy is recorded by the following two lines:\n",
    "    - eval_metric_ops={'my_accuracy': accuracy}, during evaluation.\n",
    "    - tf.summary.scalar('accuracy', accuracy[1]), during training.\n",
    "    \n",
    "These tensorboard graphs are one of the main reasons it's important to pass a global_step to your optimizer's minimize method. The model can't record the x-coordinate for these graphs without it.\n",
    "\n",
    "Note the following in the my_accuracy and loss graphs:\n",
    "\n",
    "- The orange line represents training.\n",
    "- The blue dot represents evaluation.\n",
    "\n",
    "During training, summaries (the orange line) are recorded periodically as batches are processed, which is why it becomes a graph spanning x-axis range.\n",
    "\n",
    "By contrast, evaluation produces only a single point on the graph for each call to evaluate. This point contains the average over the entire evaluation call. This has no width on the graph as it is evaluated entirely from the model state at a particular training step (from a single checkpoint).\n",
    "\n",
    "As suggested in the following figure, you may see and also selectively disable/enable the reporting using the controls on the left side.\n",
    "\n",
    "![](https://tensorflow.google.cn/images/custom_estimators/select_run.jpg)\n",
    "\n",
    "## Summary\n",
    "Although pre-made Estimators can be an effective way to quickly create new models, you will often need the additional flexibility that custom Estimators provide. Fortunately, pre-made and custom Estimators follow the same programming model. The only practical difference is that you must write a model function for custom Estimators; everything else is the same.\n",
    "\n",
    "For more details, be sure to check out:\n",
    "\n",
    "- The [official TensorFlow implementation of MNIST](https://github.com/tensorflow/models/tree/master/official/mnist), which uses a custom estimator.\n",
    "- The TensorFlow [official models repository](https://github.com/tensorflow/models/tree/master/official), which contains more curated examples using custom estimators.\n",
    "- This [TensorBoard video](https://youtu.be/eBbEDRsCmv4), which introduces TensorBoard.\n",
    "- The [Low Level Introduction](https://tensorflow.google.cn/programmers_guide/low_level_intro), which demonstrates how to experiment directly with TensorFlow's low level APIs, making debugging easier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
