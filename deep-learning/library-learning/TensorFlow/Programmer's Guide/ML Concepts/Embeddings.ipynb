{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "This document introduces the concept of embeddings, gives a simple example of\n",
    "how to train an embedding in TensorFlow, and explains how to view embeddings\n",
    "with the TensorBoard Embedding Projector\n",
    "([live example](http://projector.tensorflow.org)). The first two parts target\n",
    "newcomers to machine learning or TensorFlow, and the Embedding Projector how-to\n",
    "is for users at all levels.\n",
    "\n",
    "An alternative tutorial on these concepts is available in the\n",
    "[Embeddings section of Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture).\n",
    "\n",
    "An **embedding** is a mapping from discrete objects, such as words, to vectors\n",
    "of real numbers. For example, a 300-dimensional embedding for English words\n",
    "could include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blue:  (0.01359, 0.00075997, 0.24608, ..., -0.2524, 1.0048, 0.06259)\n",
    "blues:  (0.01396, 0.11887, -0.48963, ..., 0.033483, -0.10007, 0.1158)\n",
    "orange:  (-0.24776, -0.12359, 0.20986, ..., 0.079717, 0.23865, -0.014213)\n",
    "oranges:  (-0.35609, 0.21854, 0.080944, ..., -0.35413, 0.38511, -0.070976)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual dimensions in these vectors typically have no inherent meaning. Instead, it's the overall patterns of location and distance between vectors that machine learning takes advantage of.\n",
    "\n",
    "Embeddings are important for input to machine learning. Classifiers, and neural networks more generally, work on vectors of real numbers. They train best on dense vectors, where all values contribute to define an object. However, many important inputs to machine learning, such as words of text, do not have a natural vector representation. Embedding functions are the standard and effective way to transform such discrete input objects into useful continuous vectors.\n",
    "\n",
    "Embeddings are also valuable as outputs of machine learning. Because embeddings map objects to vectors, applications can use similarity in vector space (for instance, Euclidean distance or the angle between vectors) as a robust and flexible measure of object similarity. One common use is to find nearest neighbors. Using the same word embeddings as above, for instance, here are the three nearest neighbors for each word and the corresponding angles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blue:  (red, 47.6°), (yellow, 51.9°), (purple, 52.4°)\n",
    "blues:  (jazz, 53.3°), (folk, 59.1°), (bluegrass, 60.6°)\n",
    "orange:  (yellow, 53.5°), (colored, 58.0°), (bright, 59.9°)\n",
    "oranges:  (apples, 45.3°), (lemons, 48.3°), (mangoes, 50.4°)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would tell an application that apples and oranges are in some way more\n",
    "similar (45.3° apart) than lemons and oranges (48.3° apart).\n",
    "\n",
    "## Embeddings in TensorFlow\n",
    "\n",
    "To create word embeddings in TensorFlow, we first split the text into words\n",
    "and then assign an integer to every word in the vocabulary. Let us assume that\n",
    "this has already been done, and that `word_ids` is a vector of these integers.\n",
    "For example, the sentence “I have a cat.” could be split into\n",
    "`[“I”, “have”, “a”, “cat”, “.”]` and then the corresponding `word_ids` tensor\n",
    "would have shape `[5]` and consist of 5 integers. To map these word ids\n",
    "to vectors, we need to create the embedding variable and use the\n",
    "[`tf.nn.embedding_lookup`](https://tensorflow.google.cn/api_docs/python/tf/nn/embedding_lookup) function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embeddings = tf.get_variable(\"word_embeddings\",\n",
    "                                 [vocabulary_size, embedding_size])\n",
    "embedded_word_ids = tf.nn.embedding_lookup(word_embeddings, word_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, the tensor `embedded_word_ids` will have shape `[5, embedding_size]`\n",
    "in our example and contain the embeddings (dense vectors) for each of the 5\n",
    "words. At the end of training, `word_embeddings` will contain the embeddings\n",
    "for all words in the vocabulary.\n",
    "\n",
    "Embeddings can be trained in many network types, and with various loss\n",
    "functions and data sets. For example, one could use a recurrent neural network\n",
    "to predict the next word from the previous one given a large corpus of\n",
    "sentences, or one could train two networks to do multi-lingual translation.\n",
    "These methods are described in the @{$word2vec$Vector Representations of Words}\n",
    "tutorial.\n",
    "\n",
    "## Visualizing Embeddings\n",
    "\n",
    "TensorBoard includes the **Embedding Projector**, a tool that lets you\n",
    "interactively visualize embeddings. This tool can read embeddings from your\n",
    "model and render them in two or three dimensions.\n",
    "\n",
    "The Embedding Projector has three panels:\n",
    "\n",
    "- *Data panel* on the top left, where you can choose the run, the embedding\n",
    "  variable and data columns to color and label points by.\n",
    "- *Projections panel* on the bottom left, where you can choose the type of\n",
    "  projection.\n",
    "- *Inspector panel* on the right side, where you can search for particular\n",
    "  points and see a list of nearest neighbors.\n",
    "\n",
    "### Projections\n",
    "The Embedding Projector provides three ways to reduce the dimensionality of a\n",
    "data set.\n",
    "\n",
    "- *[t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)*:\n",
    "  a nonlinear nondeterministic algorithm (T-distributed stochastic neighbor\n",
    "  embedding) that tries to preserve local neighborhoods in the data, often at\n",
    "  the expense of distorting global structure. You can choose whether to compute\n",
    "  two- or three-dimensional projections.\n",
    "\n",
    "- *[PCA](https://en.wikipedia.org/wiki/Principal_component_analysis)*:\n",
    "  a linear deterministic algorithm (principal component analysis) that tries to\n",
    "  capture as much of the data variability in as few dimensions as possible. PCA\n",
    "  tends to highlight large-scale structure in the data, but can distort local\n",
    "  neighborhoods. The Embedding Projector computes the top 10 principal\n",
    "  components, from which you can choose two or three to view.\n",
    "\n",
    "- *Custom*: a linear projection onto horizontal and vertical axes that you\n",
    "  specify using labels in the data. You define the horizontal axis, for\n",
    "  instance, by giving text patterns for \"Left\" and \"Right\". The Embedding\n",
    "  Projector finds all points whose label matches the \"Left\" pattern and\n",
    "  computes the centroid of that set; similarly for \"Right\".  The line passing\n",
    "  through these two centroids defines the horizontal axis. The vertical axis is\n",
    "  likewise computed from the centroids for points matching the \"Up\" and \"Down\"\n",
    "  text patterns.\n",
    "\n",
    "Further useful articles are\n",
    "[How to Use t-SNE Effectively](https://distill.pub/2016/misread-tsne/) and\n",
    "[Principal Component Analysis Explained Visually](http://setosa.io/ev/principal-component-analysis/).\n",
    "\n",
    "### Exploration\n",
    "\n",
    "You can explore visually by zooming, rotating, and panning using natural\n",
    "click-and-drag gestures. Hovering your mouse over a point will show any\n",
    "[metadata](#metadata) for that point.  You can also inspect nearest-neighbor\n",
    "subsets.  Clicking on a point causes the right pane to list the nearest\n",
    "neighbors, along with distances to the current point. The nearest-neighbor\n",
    "points are also highlighted in the projection.\n",
    "\n",
    "It is sometimes useful to restrict the view to a subset of points and perform\n",
    "projections only on those points. To do so, you can select points in multiple\n",
    "ways:\n",
    "\n",
    "- After clicking on a point, its nearest neighbors are also selected.\n",
    "- After a search, the points matching the query are selected.\n",
    "- Enabling selection, clicking on a point and dragging defines a selection\n",
    "  sphere.\n",
    "\n",
    "Then click the \"Isolate *nnn* points\" button at the top of the Inspector pane\n",
    "on the right hand side. The following image shows 101 points selected and ready\n",
    "for the user to click \"Isolate 101 points\":\n",
    "\n",
    "![Selection of nearest neighbors](https://tensorflow.google.cn/images/embedding-nearest-points.png \"Selection of nearest neighbors\")\n",
    "\n",
    "*Selection of the nearest neighbors of “important” in a word embedding dataset.*\n",
    "\n",
    "Advanced tip: filtering with custom projection can be powerful. Below, we\n",
    "filtered the 100 nearest neighbors of “politics” and projected them onto the\n",
    "“worst” - “best” vector as an x axis. The y axis is random. As a result, one\n",
    "finds on the right side “ideas”, “science”, “perspective”, “journalism” but on\n",
    "the left “crisis”, “violence” and “conflict”.\n",
    "\n",
    "<table width=\"100%;\">\n",
    "  <tr>\n",
    "    <td style=\"width: 30%;\">\n",
    "      <img src=\"https://tensorflow.google.cn/images/embedding-custom-controls.png\" alt=\"Custom controls panel\" title=\"Custom controls panel\" />\n",
    "    </td>\n",
    "    <td style=\"width: 70%;\">\n",
    "      <img src=\"https://tensorflow.google.cn/images/embedding-custom-projection.png\" alt=\"Custom projection\" title=\"Custom projection\" />\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"width: 30%;\">\n",
    "      Custom projection controls.\n",
    "    </td>\n",
    "    <td style=\"width: 70%;\">\n",
    "      Custom projection of neighbors of \"politics\" onto \"best\" - \"worst\" vector.\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "To share your findings, you can use the bookmark panel in the bottom right\n",
    "corner and save the current state (including computed coordinates of any\n",
    "projection) as a small file. The Projector can then be pointed to a set of one\n",
    "or more of these files, producing the panel below. Other users can then walk\n",
    "through a sequence of bookmarks.\n",
    "\n",
    "<img src=\"https://tensorflow.google.cn/images/embedding-bookmark.png\" alt=\"Bookmark panel\" style=\"width:300px;\">\n",
    "\n",
    "### Metadata\n",
    "\n",
    "If you are working with an embedding, you'll probably want to attach\n",
    "labels/images to the data points. You can do this by generating a metadata file\n",
    "containing the labels for each point and clicking \"Load data\" in the data panel\n",
    "of the Embedding Projector.\n",
    "\n",
    "The metadata can be either labels or images, which are\n",
    "stored in a separate file. For labels, the format should\n",
    "be a [TSV file](https://en.wikipedia.org/wiki/Tab-separated_values)\n",
    "(tab characters shown in red) whose first line contains column headers\n",
    "(shown in bold) and subsequent lines contain the metadata values. For example:\n",
    "\n",
    "<code>\n",
    "<b>Word<span style=\"color:#800;\">\\t</span>Frequency</b><br/>\n",
    "  Airplane<span style=\"color:#800;\">\\t</span>345<br/>\n",
    "  Car<span style=\"color:#800;\">\\t</span>241<br/>\n",
    "  ...\n",
    "</code>\n",
    "\n",
    "The order of lines in the metadata file is assumed to match the order of\n",
    "vectors in the embedding variable, except for the header.  Consequently, the\n",
    "(i+1)-th line in the metadata file corresponds to the i-th row of the embedding\n",
    "variable.  If the TSV metadata file has only a single column, then we don’t\n",
    "expect a header row, and assume each row is the label of the embedding. We\n",
    "include this exception because it matches the commonly-used \"vocab file\"\n",
    "format.\n",
    "\n",
    "To use images as metadata, you must produce a single\n",
    "[sprite image](https://www.google.com/webhp#q=what+is+a+sprite+image),\n",
    "consisting of small thumbnails, one for each vector in the embedding.  The\n",
    "sprite should store thumbnails in row-first order: the first data point placed\n",
    "in the top left and the last data point in the bottom right, though the last\n",
    "row doesn't have to be filled, as shown below.\n",
    "\n",
    "<table style=\"border: none;\">\n",
    "<tr style=\"background-color: transparent;\">\n",
    "  <td style=\"border: 1px solid black\">0</td>\n",
    "  <td style=\"border: 1px solid black\">1</td>\n",
    "  <td style=\"border: 1px solid black\">2</td>\n",
    "</tr>\n",
    "<tr style=\"background-color: transparent;\">\n",
    "  <td style=\"border: 1px solid black\">3</td>\n",
    "  <td style=\"border: 1px solid black\">4</td>\n",
    "  <td style=\"border: 1px solid black\">5</td>\n",
    "</tr>\n",
    "<tr style=\"background-color: transparent;\">\n",
    "  <td style=\"border: 1px solid black\">6</td>\n",
    "  <td style=\"border: 1px solid black\">7</td>\n",
    "  <td style=\"border: 1px solid black\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Follow [this link](https://www.tensorflow.org/images/embedding-mnist.mp4)\n",
    "to see a fun example of thumbnail images in the Embedding Projector.\n",
    "\n",
    "\n",
    "## Mini-FAQ\n",
    "\n",
    "**Is \"embedding\" an action or a thing?**\n",
    "Both. People talk about embedding words in a vector space (action) and about\n",
    "producing word embeddings (things).  Common to both is the notion of embedding\n",
    "as a mapping from discrete objects to vectors. Creating or applying that\n",
    "mapping is an action, but the mapping itself is a thing.\n",
    "\n",
    "**Are embeddings high-dimensional or low-dimensional?**\n",
    "It depends. A 300-dimensional vector space of words and phrases, for instance,\n",
    "is often called low-dimensional (and dense) when compared to the millions of\n",
    "words and phrases it can contain. But mathematically it is high-dimensional,\n",
    "displaying many properties that are dramatically different from what our human\n",
    "intuition has learned about 2- and 3-dimensional spaces.\n",
    "\n",
    "**Is an embedding the same as an embedding layer?**\n",
    "No. An *embedding layer* is a part of neural network, but an *embedding* is a more\n",
    "general concept."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
