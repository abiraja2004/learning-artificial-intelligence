{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Restore\n",
    "\n",
    "The [tf.train.Saver](https://tensorflow.google.cn/api_docs/python/tf/train/Saver) class provides methods to save and restore models. The\n",
    "[tf.saved_model.simple_save](https://tensorflow.google.cn/api_docs/python/tf/saved_model/simple_save) function is an easy way to build a\n",
    "[saved model](https://tensorflow.google.cn/api_docs/python/tf/saved_model) suitable for serving.\n",
    "[Estimators](@{$guide/estimators}) automatically save and restore\n",
    "variables in the `model_dir`.\n",
    "\n",
    "## Save and restore variables\n",
    "\n",
    "TensorFlow [Variables](https://tensorflow.google.cn/programmers_guide/variables) are the best way to represent shared, persistent state\n",
    "manipulated by your program. The `tf.train.Saver` constructor adds `save` and\n",
    "`restore` ops to the graph for all, or a specified list, of the variables in the\n",
    "graph.  The `Saver` object provides methods to run these ops, specifying paths\n",
    "for the checkpoint files to write to or read from.\n",
    "\n",
    "`Saver` restores all variables already defined in your model. If you're\n",
    "loading a model without knowing how to build its graph (for example, if you're\n",
    "writing a generic program to load models), then read the\n",
    "[Overview of saving and restoring models](#models) section\n",
    "later in this document.\n",
    "\n",
    "TensorFlow saves variables in binary *checkpoint files* that map variable\n",
    "names to tensor values.\n",
    "\n",
    "> Caution: TensorFlow model files are code. Be careful with untrusted code.\n",
    "See [Using TensorFlow Securely](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md)\n",
    "for details.\n",
    "\n",
    "### Save variables\n",
    "\n",
    "Create a `Saver` with `tf.train.Saver()` to manage all variables in the\n",
    "model. For example, the following snippet demonstrates how to call the\n",
    "`tf.train.Saver.save` method to save variables to checkpoint files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in path: /tmp/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", shape=[3], initializer = tf.zeros_initializer)\n",
    "v2 = tf.get_variable(\"v2\", shape=[5], initializer = tf.zeros_initializer)\n",
    "\n",
    "inc_v1 = v1.assign(v1+1)\n",
    "dec_v2 = v2.assign(v2-1)\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, and save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    # Do some work with the model.\n",
    "    inc_v1.op.run()\n",
    "    dec_v2.op.run()\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore variables\n",
    "\n",
    "The [`tf.train.Saver`](https://tensorflow.google.cn/api_docs/python/tf/train/Saver) object not only saves variables to checkpoint files, it\n",
    "also restores variables. Note that when you restore variables you do not have\n",
    "to initialize them beforehand. For example, the following snippet demonstrates\n",
    "how to call the [`tf.train.Saver.restore`](https://tensorflow.google.cn/api_docs/python/tf/train/Saver#restore) method to restore variables from the\n",
    "checkpoint files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Model restored.\n",
      "v1 : [1. 1. 1.]\n",
      "v2 : [-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", shape=[3])\n",
    "v2 = tf.get_variable(\"v2\", shape=[5])\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    # Check the values of the variables\n",
    "    print(\"v1 : %s\" % v1.eval())\n",
    "    print(\"v2 : %s\" % v2.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: There is not a physical file called `/tmp/model.ckpt`. It is the *prefix* of\n",
    "filenames created for the checkpoint. Users only interact with the prefix\n",
    "instead of physical checkpoint files.\n",
    "\n",
    "### Choose variables to save and restore\n",
    "\n",
    "If you do not pass any arguments to `tf.train.Saver()`, the saver handles all\n",
    "variables in the graph.  Each variable is saved under the name that was passed\n",
    "when the variable was created.\n",
    "\n",
    "It is sometimes useful to explicitly specify names for variables in the\n",
    "checkpoint files.  For example, you may have trained a model with a variable\n",
    "named `\"weights\"` whose value you want to restore into a variable named\n",
    "`\"params\"`.\n",
    "\n",
    "It is also sometimes useful to only save or restore a subset of the variables\n",
    "used by a model.  For example, you may have trained a neural net with five\n",
    "layers, and you now want to train a new model with six layers that reuses the\n",
    "existing weights of the five trained layers. You can use the saver to restore\n",
    "the weights of just the first five layers.\n",
    "\n",
    "You can easily specify the names and variables to save or load by passing to the\n",
    "`tf.train.Saver()` constructor either of the following:\n",
    "\n",
    "* A list of variables (which will be stored under their own names).\n",
    "* A Python dictionary in which keys are the names to use and the values are the\n",
    "variables to manage.\n",
    "\n",
    "Continuing from the save/restore examples shown earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "v1 : [0. 0. 0.]\n",
      "v2 : [-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Create some variables.\n",
    "v1 = tf.get_variable(\"v1\", [3], initializer = tf.zeros_initializer)\n",
    "v2 = tf.get_variable(\"v2\", [5], initializer = tf.zeros_initializer)\n",
    "\n",
    "# Add ops to save and restore only `v2` using the name \"v2\"\n",
    "saver = tf.train.Saver({\"v2\": v2})\n",
    "\n",
    "# Use the saver object normally after that.\n",
    "with tf.Session() as sess:\n",
    "    # Initialize v1 since the saver will not.\n",
    "    v1.initializer.run()\n",
    "    saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "\n",
    "    print(\"v1 : %s\" % v1.eval())\n",
    "    print(\"v2 : %s\" % v2.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "*  You can create as many `Saver` objects as you want if you need to save and\n",
    "   restore different subsets of the model variables.  The same variable can be\n",
    "   listed in multiple saver objects; its value is only changed when the\n",
    "   `Saver.restore()` method is run.\n",
    "\n",
    "*  If you only restore a subset of the model variables at the start of a\n",
    "   session, you have to run an initialize op for the other variables.  See\n",
    "   [tf.variables_initializer](https://tensorflow.google.cn/api_docs/python/tf/variables_initializer) for more information.\n",
    "\n",
    "*  To inspect the variables in a checkpoint, you can use the\n",
    "   [`inspect_checkpoint`](https://www.tensorflow.org/code/tensorflow/python/tools/inspect_checkpoint.py)\n",
    "   library, particularly the `print_tensors_in_checkpoint_file` function.\n",
    "\n",
    "*  By default, `Saver` uses the value of the [tf.Variable.name](https://tensorflow.google.cn/api_docs/python/tf/Variable#name) property\n",
    "   for each variable.  However, when you create a `Saver` object, you may\n",
    "   optionally choose names for the variables in the checkpoint files.\n",
    "\n",
    "\n",
    "### Inspect variables in a checkpoint\n",
    "\n",
    "We can quickly inspect variables in a checkpoint with the\n",
    "[`inspect_checkpoint`](https://www.tensorflow.org/code/tensorflow/python/tools/inspect_checkpoint.py) library.\n",
    "\n",
    "Continuing from the save/restore examples shown earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name:  v1\n",
      "[1. 1. 1.]\n",
      "tensor_name:  v2\n",
      "[-1. -1. -1. -1. -1.]\n",
      "tensor_name:  v1\n",
      "[1. 1. 1.]\n",
      "tensor_name:  v2\n",
      "[-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# import the inspect_checkpoint library\n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "\n",
    "# print all tensors in checkpoint file\n",
    "chkp.print_tensors_in_checkpoint_file(\"/tmp/model.ckpt\", tensor_name=\"\", all_tensors=True)\n",
    "\n",
    "# tensor_name:  v1\n",
    "# [ 1.  1.  1.]\n",
    "# tensor_name:  v2\n",
    "# [-1. -1. -1. -1. -1.]\n",
    "\n",
    "# print only tensor v1 in checkpoint file\n",
    "chkp.print_tensors_in_checkpoint_file(\"/tmp/model.ckpt\", tensor_name='v1', all_tensors=False)\n",
    "\n",
    "# tensor_name:  v1\n",
    "# [ 1.  1.  1.]\n",
    "\n",
    "# print only tensor v2 in checkpoint file\n",
    "chkp.print_tensors_in_checkpoint_file(\"/tmp/model.ckpt\", tensor_name='v2', all_tensors=False)\n",
    "\n",
    "# tensor_name:  v2\n",
    "# [-1. -1. -1. -1. -1.] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and restore models\n",
    "\n",
    "Use `SavedModel` to save and load your model—variables, the graph, and the\n",
    "graph's metadata. This is a language-neutral, recoverable, hermetic\n",
    "serialization format that enables higher-level systems and tools to produce,\n",
    "consume, and transform TensorFlow models. TensorFlow provides several ways to\n",
    "interact with `SavedModel`, including the [tf.saved_model](https://tensorflow.google.cn/api_docs/python/tf/saved_model) APIs,\n",
    "[tf.estimator.Estimator](https://tensorflow.google.cn/api_docs/python/tf/estimator/Estimator), and a command-line interface.\n",
    "\n",
    "\n",
    "## Build and load a SavedModel\n",
    "\n",
    "### Simple save\n",
    "\n",
    "The easiest way to create a `SavedModel` is to use the [tf.saved_model.simple_save](https://tensorflow.google.cn/api_docs/python/tf/saved_model/simple_save)\n",
    "function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_save(session,\n",
    "            export_dir,\n",
    "            inputs={\"x\": x, \"y\": y},\n",
    "            outputs={\"z\": z})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This configures the `SavedModel` so it can be loaded by\n",
    "[TensorFlow serving](/serving/serving_basic) and supports the\n",
    "[Predict API](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/predict.proto).\n",
    "To access the classify, regress, or multi-inference APIs, use the manual\n",
    "`SavedModel` builder APIs or an [tf.estimator.Estimator](https://tensorflow.google.cn/api_docs/python/tf/estimator/Estimator).\n",
    "\n",
    "### Manually build a SavedModel\n",
    "\n",
    "If your use case isn't covered by [tf.saved_model.simple_save](https://tensorflow.google.cn/api_docs/python/tf/saved_model/simple_save), use the manual\n",
    "[builder APIs](https://tensorflow.google.cn/api_docs/python/tf/saved_model/builder) to create a `SavedModel`.\n",
    "\n",
    "The [tf.saved_model.builder.SavedModelBuilder](https://tensorflow.google.cn/api_docs/python/tf/saved_model/builder/SavedModelBuilder) class provides functionality to\n",
    "save multiple `MetaGraphDef`s.  A **MetaGraph** is a dataflow graph, plus\n",
    "its associated variables, assets, and signatures.  A **`MetaGraphDef`**\n",
    "is the protocol buffer representation of a MetaGraph.  A **signature** is\n",
    "the set of inputs to and outputs from a graph.\n",
    "\n",
    "If assets need to be saved and written or copied to disk, they can be provided\n",
    "when the first `MetaGraphDef` is added. If multiple `MetaGraphDef`s are\n",
    "associated with an asset of the same name, only the first version is retained.\n",
    "\n",
    "Each `MetaGraphDef` added to the SavedModel must be annotated with\n",
    "user-specified tags. The tags provide a means to identify the specific\n",
    "`MetaGraphDef` to load and restore, along with the shared set of variables\n",
    "and assets. These tags\n",
    "typically annotate a `MetaGraphDef` with its functionality (for example,\n",
    "serving or training), and optionally with hardware-specific aspects (for\n",
    "example, GPU).\n",
    "\n",
    "For example, the following code suggests a typical way to use\n",
    "`SavedModelBuilder` to build a SavedModel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_dir = ...\n",
    "...\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    ...\n",
    "    builder.add_meta_graph_and_variables(sess,\n",
    "                                       [tag_constants.TRAINING],\n",
    "                                       signature_def_map=foo_signatures,\n",
    "                                       assets_collection=foo_assets,\n",
    "                                       strip_default_attrs=True)\n",
    "...\n",
    "# Add a second MetaGraphDef for inference.\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    ...\n",
    "    builder.add_meta_graph([tag_constants.SERVING], strip_default_attrs=True)\n",
    "...\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward compatibility via `strip_default_attrs=True`\n",
    "\n",
    "Following the guidance below gives you forward compatibility only if the set of\n",
    "Ops has not changed.\n",
    "\n",
    "The [SavedModelBuilder](https://tensorflow.google.cn/api_docs/python/tf/saved_model/builder/SavedModelBuilder) class allows\n",
    "users to control whether default-valued attributes must be stripped from the\n",
    "[NodeDefs](https://tensorflow.google.cn/extend/tool_developers/index#nodes)\n",
    "while adding a meta graph to the SavedModel bundle. Both\n",
    "[SavedModelBuilder.add_meta_graph_and_variables](https://tensorflow.google.cn/api_docs/python/tf/saved_model/builder/SavedModelBuilder#add_meta_graph_and_variables)\n",
    "and [SavedModelBuilder.add_meta_graph](https://tensorflow.google.cn/api_docs/python/tf/saved_model/builder/SavedModelBuilder#add_meta_graph)\n",
    "methods accept a Boolean flag `strip_default_attrs` that controls this behavior.\n",
    "\n",
    "If `strip_default_attrs` is `False`, the exported [tf.MetaGraphDef](https://tensorflow.google.cn/api_docs/python/tf/MetaGraphDef) will have\n",
    "the default valued attributes in all its [tf.NodeDef](https://tensorflow.google.cn/api_docs/python/tf/NodeDef) instances.\n",
    "This can break forward compatibility with a sequence of events such as the\n",
    "following:\n",
    "\n",
    "*  An existing Op (`Foo`) is updated to include a new attribute (`T`) with a\n",
    "   default (`bool`) at version 101.\n",
    "*  A model producer such as a \"trainer binary\" picks up this change (version 101)\n",
    "   to the `OpDef` and re-exports an existing model that uses Op `Foo`.\n",
    "*  A model consumer (such as [Tensorflow Serving](/serving)) running an older\n",
    "   binary (version 100) doesn't have attribute `T` for Op `Foo`, but tries to\n",
    "   import this model. The model consumer doesn't recognize attribute `T` in a\n",
    "   `NodeDef` that uses Op `Foo` and therefore fails to load the model.\n",
    "*  By setting `strip_default_attrs` to True, the model producers can strip away\n",
    "   any default valued attributes in the `NodeDefs`. This helps ensure that newly\n",
    "   added attributes with defaults don't cause older model consumers to fail\n",
    "   loading models regenerated with newer training binaries.\n",
    "\n",
    "See [compatibility guidance](./version_compat.md)\n",
    "for more information.\n",
    "\n",
    "### Loading a SavedModel in Python\n",
    "\n",
    "The Python version of the SavedModel\n",
    "[loader](https://tensorflow.google.cn/api_docs/python/tf/saved_model/loader)\n",
    "provides load and restore capability for a SavedModel. The `load` operation\n",
    "requires the following information:\n",
    "\n",
    "* The session in which to restore the graph definition and variables.\n",
    "* The tags used to identify the MetaGraphDef to load.\n",
    "* The location (directory) of the SavedModel.\n",
    "\n",
    "Upon a load, the subset of variables, assets, and signatures supplied as part of\n",
    "the specific MetaGraphDef will be restored into the supplied session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_dir = ...\n",
    "...\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, [tag_constants.TRAINING], export_dir)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a SavedModel in C++\n",
    "\n",
    "The C++ version of the SavedModel\n",
    "[loader](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/saved_model/loader.h)\n",
    "provides an API to load a SavedModel from a path, while allowing\n",
    "`SessionOptions` and `RunOptions`.\n",
    "You have to specify the tags associated with the graph to be loaded.\n",
    "The loaded version of SavedModel is referred to as `SavedModelBundle`\n",
    "and contains the MetaGraphDef and the session within which it is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "const string export_dir = ...\n",
    "SavedModelBundle bundle;\n",
    "...\n",
    "LoadSavedModel(session_options, run_options, export_dir, {kSavedModelTagTrain},\n",
    "               &bundle);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and serve a SavedModel in TensorFlow serving\n",
    "\n",
    "You can easily load and serve a SavedModel with the TensorFlow Serving Model\n",
    "Server binary. See [instructions](https://www.tensorflow.org/serving/setup#installing_using_apt-get)\n",
    "on how to install the server, or build it if you wish.\n",
    "\n",
    "Once you have the Model Server, run it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensorflow_model_server --port=port-numbers --model_name=your-model-name --model_base_path=your_model_base_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the port and model_name flags to values of your choosing. The\n",
    "model_base_path flag expects to be to a base directory, with each version of\n",
    "your model residing in a numerically named subdirectory. If you only have a\n",
    "single version of your model, simply place it in a subdirectory like so:\n",
    "* Place the model in /tmp/model/0001\n",
    "* Set model_base_path to /tmp/model\n",
    "\n",
    "Store different versions of your model in numerically named subdirectories of a\n",
    "common base directory. For example, suppose the base directory is `/tmp/model`.\n",
    "If you have only one version of your model, store it in `/tmp/model/0001`. If\n",
    "you have two versions of your model, store the second version in\n",
    "`/tmp/model/0002`, and so on.  Set the `--model-base_path` flag to the base\n",
    "directory (`/tmp/model`, in this example).  TensorFlow Model Server will serve\n",
    "the model in the highest numbered subdirectory of that base directory.\n",
    "\n",
    "### Standard constants\n",
    "\n",
    "SavedModel offers the flexibility to build and load TensorFlow graphs for a\n",
    "variety of use-cases. For the most common use-cases, SavedModel's APIs\n",
    "provide a set of constants in Python and C++ that are easy to\n",
    "reuse and share across tools consistently.\n",
    "\n",
    "#### Standard MetaGraphDef tags\n",
    "\n",
    "You may use sets of tags to uniquely identify a `MetaGraphDef` saved in a\n",
    "SavedModel. A subset of commonly used tags is specified in:\n",
    "\n",
    "* [Python](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/tag_constants.py)\n",
    "* [C++](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/saved_model/tag_constants.h)\n",
    "\n",
    "## Using SavedModel with Estimators\n",
    "\n",
    "After training an `Estimator` model, you may want to create a service\n",
    "from that model that takes requests and returns a result.  You can run such a\n",
    "service locally on your machine or deploy it in the cloud.\n",
    "\n",
    "To prepare a trained Estimator for serving, you must export it in the standard\n",
    "SavedModel format. This section explains how to:\n",
    "\n",
    "* Specify the output nodes and the corresponding\n",
    "  [APIs](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/prediction_service.proto)\n",
    "  that can be served (Classify, Regress, or Predict).\n",
    "* Export your model to the SavedModel format.\n",
    "* Serve the model from a local server and request predictions.\n",
    "\n",
    "\n",
    "### Prepare serving inputs\n",
    "\n",
    "During training, an [`input_fn()`](https://tensorflow.google.cn/get_started/premade_estimators#input_fn) ingests data\n",
    "and prepares it for use by the model.  At serving time, similarly, a\n",
    "`serving_input_receiver_fn()` accepts inference requests and prepares them for\n",
    "the model.  This function has the following purposes:\n",
    "\n",
    "*  To add placeholders to the graph that the serving system will feed\n",
    "   with inference requests.\n",
    "*  To add any additional ops needed to convert data from the input format\n",
    "   into the feature `Tensor`s expected by the model.\n",
    "\n",
    "The function returns a [tf.estimator.export.ServingInputReceiver](https://tensorflow.google.cn/api_docs/python/tf/estimator/export/ServingInputReceiver) object,\n",
    "which packages the placeholders and the resulting feature `Tensor`s together.\n",
    "\n",
    "A typical pattern is that inference requests arrive in the form of serialized\n",
    "`tf.Example`s, so the `serving_input_receiver_fn()` creates a single string\n",
    "placeholder to receive them.  The `serving_input_receiver_fn()` is then also\n",
    "responsible for parsing the `tf.Example`s by adding a [tf.parse_example](https://tensorflow.google.cn/api_docs/python/tf/parse_example) op to\n",
    "the graph.\n",
    "\n",
    "When writing such a `serving_input_receiver_fn()`, you must pass a parsing\n",
    "specification to [tf.parse_example](https://tensorflow.google.cn/api_docs/python/tf/parse_example) to tell the parser what feature names to\n",
    "expect and how to map them to `Tensor`s. A parsing specification takes the\n",
    "form of a dict from feature names to [tf.FixedLenFeature](https://tensorflow.google.cn/api_docs/python/tf/FixedLenFeature), [tf.VarLenFeature](https://tensorflow.google.cn/api_docs/python/tf/VarLenFeature),\n",
    "and [tf.SparseFeature](https://tensorflow.google.cn/api_docs/python/tf/SparseFeature).  Note this parsing specification should not include\n",
    "any label or weight columns, since those will not be available at serving\n",
    "time&mdash;in contrast to a parsing specification used in the `input_fn()` at\n",
    "training time.\n",
    "\n",
    "In combination, then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_spec = {'foo': tf.FixedLenFeature(...),\n",
    "                'bar': tf.VarLenFeature(...)}\n",
    "\n",
    "def serving_input_receiver_fn():\n",
    "    \"\"\"An input receiver that expects a serialized tf.Example.\"\"\"\n",
    "    serialized_tf_example = tf.placeholder(dtype=tf.string,\n",
    "                                         shape=[default_batch_size],\n",
    "                                         name='input_example_tensor')\n",
    "    receiver_tensors = {'examples': serialized_tf_example}\n",
    "    features = tf.parse_example(serialized_tf_example, feature_spec)\n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
