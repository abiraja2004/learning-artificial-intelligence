{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "A TensorFlow **variable** is the best way to represent shared, persistent state manipulated by your program.\n",
    "\n",
    "Variables are manipulated via the [tf.Variable](https://tensorflow.google.cn/api_docs/python/tf/Variable) class. A [tf.Variable](https://tensorflow.google.cn/api_docs/python/tf/Variable) represents a tensor whose value can be changed by running ops on it. Unlike [tf.Tensor](https://tensorflow.google.cn/api_docs/python/tf/Tensor) objects, a [tf.Variable](https://tensorflow.google.cn/api_docs/python/tf/Variable) exists outside the context of a single session.run call.\n",
    "\n",
    "Internally, a [tf.Variable](https://tensorflow.google.cn/api_docs/python/tf/Variable) stores a persistent tensor. Specific ops allow you to read and modify the values of this tensor. These modifications are visible across multiple [tf.Sessions](https://tensorflow.google.cn/api_docs/python/tf/Session), so multiple workers can see the same values for a [tf.Variable](https://tensorflow.google.cn/api_docs/python/tf/Variable).\n",
    "\n",
    "## Creating a Variable\n",
    "The best way to create a variable is to call the [tf.get_variable](https://tensorflow.google.cn/api_docs/python/tf/get_variable) function. This function requires you to specify the Variable's name. This name will be used by other replicas to access the same variable, as well as to name this variable's value when checkpointing and exporting models. [tf.get_variable](https://tensorflow.google.cn/api_docs/python/tf/get_variable) also allows you to reuse a previously created variable of the same name, making it easy to define models which reuse layers.\n",
    "\n",
    "To create a variable with [tf.get_variable](https://tensorflow.google.cn/api_docs/python/tf/get_variable), simply provide the name and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "my_variable = tf.get_variable(\"my_variable\", [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a variable named \"my_variable\" which is a three-dimensional tensor with shape [1, 2, 3]. This variable will, by default, have the dtype [tf.float32](https://tensorflow.google.cn/api_docs/python/tf/float32) and its initial value will be randomized via [tf.glorot_uniform_initializer](https://tensorflow.google.cn/api_docs/python/tf/glorot_uniform_initializer).\n",
    "\n",
    "You may optionally specify the dtype and initializer to [tf.get_variable](https://tensorflow.google.cn/api_docs/python/tf/get_variable). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_int_variable = tf.get_variable(\"my_int_variable\", [1, 2, 3], dtype=tf.int32,\n",
    "                                 initializer=tf.zeros_initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow provides many convenient initializers. Alternatively, you may initialize a [tf.Variable](https://tensorflow.google.cn/api_docs/python/tf/Variable) to have the value of a [tf.Tensor](https://tensorflow.google.cn/api_docs/python/tf/Tensor). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_variable = tf.get_variable(\"other_variable\", dtype=tf.int32,\n",
    "  initializer=tf.constant([23, 42]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when the initializer is a [tf.Tensor](https://tensorflow.google.cn/api_docs/python/tf/Tensor) you should not specify the variable's shape, as the shape of the initializer tensor will be used.\n",
    "\n",
    "### Variable collections\n",
    "Because disconnected parts of a TensorFlow program might want to create variables, it is sometimes useful to have a single way to access all of them. For this reason TensorFlow provides **collections**, which are named lists of tensors or other objects, such as [tf.Variable](https://tensorflow.google.cn/api_docs/python/tf/Variable) instances.\n",
    "\n",
    "By default every [tf.Variable](https://tensorflow.google.cn/api_docs/python/tf/Variable) gets placed in the following two collections:\n",
    "\n",
    "- [tf.GraphKeys.GLOBAL_VARIABLES](https://tensorflow.google.cn/api_docs/python/tf/GraphKeys#GLOBAL_VARIABLES) --- variables that can be shared across multiple devices,\n",
    "- [tf.GraphKeys.TRAINABLE_VARIABLES](https://tensorflow.google.cn/api_docs/python/tf/GraphKeys#TRAINABLE_VARIABLES) --- variables for which TensorFlow will calculate gradients.\n",
    "\n",
    "If you don't want a variable to be trainable, add it to the [tf.GraphKeys.LOCAL_VARIABLES](https://tensorflow.google.cn/api_docs/python/tf/GraphKeys#LOCAL_VARIABLES) collection instead. For example, the following snippet demonstrates how to add a variable named my_local to this collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_local = tf.get_variable(\"my_local\", shape=(),\n",
    "                           collections=[tf.GraphKeys.LOCAL_VARIABLES])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can specify trainable=False as an argument to [tf.get_variable](https://tensorflow.google.cn/api_docs/python/tf/get_variable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_non_trainable = tf.get_variable(\"my_non_trainable\",\n",
    "                                   shape=(),\n",
    "                                   trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use your own collections. Any string is a valid collection name, and there is no need to explicitly create a collection. To add a variable (or any other object) to a collection after creating the variable, call [tf.add_to_collection](https://tensorflow.google.cn/api_docs/python/tf/add_to_collection). For example, the following code adds an existing variable named my_local to a collection named my_collection_name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.add_to_collection(\"my_collection_name\", my_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to retrieve a list of all the variables (or other objects) you've placed in a collection you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'my_local:0' shape=() dtype=float32_ref>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(\"my_collection_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device placement\n",
    "Just like any other TensorFlow operation, you can place variables on particular devices. For example, the following snippet creates a variable named v and places it on the second GPU device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:1\"):\n",
    "    v = tf.get_variable(\"v\", [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is particularly important for variables to be in the correct device in distributed settings. Accidentally putting variables on workers instead of parameter servers, for example, can severely slow down training or, in the worst case, let each worker blithely forge ahead with its own independent copy of each variable. For this reason we provide [tf.train.replica_device_setter](https://tensorflow.google.cn/api_docs/python/tf/train/replica_device_setter), which can automatically place variables in parameter servers. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_spec = {\n",
    "    \"ps\": [\"ps0:2222\", \"ps1:2222\"],\n",
    "    \"worker\": [\"worker0:2222\", \"worker1:2222\", \"worker2:2222\"]}\n",
    "with tf.device(tf.train.replica_device_setter(cluster=cluster_spec)):\n",
    "    v1 = tf.get_variable(\"v1\", shape=[20, 20])  # this variable is placed\n",
    "                                            # in the parameter server\n",
    "                                            # by the replica_device_setter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing variables\n",
    "Before you can use a variable, it must be initialized. If you are programming in the low-level TensorFlow API (that is, you are explicitly creating your own graphs and sessions), you must explicitly initialize the variables. Most high-level frameworks such as [tf.contrib.slim](https://tensorflow.google.cn/api_docs/python/tf/contrib/slim), [tf.estimator.Estimator](https://tensorflow.google.cn/api_docs/python/tf/estimator/Estimator) and Keras automatically initialize variables for you before training a model.\n",
    "\n",
    "Explicit initialization is otherwise useful because it allows you not to rerun potentially expensive initializers when reloading a model from a checkpoint as well as allowing determinism when randomly-initialized variables are shared in a distributed setting.\n",
    "\n",
    "To initialize all trainable variables in one go, before training starts, call tf.global_variables_initializer(). This function returns a single operation responsible for initializing all variables in the [tf.GraphKeys.GLOBAL_VARIABLES](https://tensorflow.google.cn/api_docs/python/tf/GraphKeys#GLOBAL_VARIABLES) collection. Running this operation initializes all variables. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "# Now all variables are initialized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do need to initialize variables yourself, you can run the variable's initializer operation. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(my_variable.initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also ask which variables have still not been initialized. For example, the following code prints the names of all variables which have not yet been initialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(session.run(tf.report_uninitialized_variables()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by default [tf.global_variables_initializer](https://tensorflow.google.cn/api_docs/python/tf/global_variables_initializer) does not specify the order in which variables are initialized. Therefore, if the initial value of a variable depends on another variable's value, it's likely that you'll get an error. Any time you use the value of a variable in a context in which not all variables are initialized (say, if you use a variable's value while initializing another variable), it is best to use variable.initialized_value() instead of variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\n",
    "w = tf.get_variable(\"w\", initializer=v.initialized_value() + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using variables\n",
    "To use the value of a [tf.Variable](https://tensorflow.google.cn/api_docs/python/tf/Variable) in a TensorFlow graph, simply treat it like a normal [tf.Tensor](https://tensorflow.google.cn/api_docs/python/tf/Tensor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\n",
    "w = v + 1  # w is a tf.Tensor which is computed based on the value of v.\n",
    "           # Any time a variable is used in an expression it gets automatically\n",
    "           # converted to a tf.Tensor representing its value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assign a value to a variable, use the methods assign, assign_add, and friends in the [tf.Variable](https://tensorflow.google.cn/api_docs/python/tf/Variable) class. For example, here is how you can call these methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\n",
    "assignment = v.assign_add(1)\n",
    "tf.global_variables_initializer().run()\n",
    "sess.run(assignment)  # or assignment.op.run(), or assignment.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most TensorFlow optimizers have specialized ops that efficiently update the values of variables according to some gradient descent-like algorithm. See [tf.train.Optimizer](https://tensorflow.google.cn/api_docs/python/tf/train/Optimizer) for an explanation of how to use optimizers.\n",
    "\n",
    "Because variables are mutable it's sometimes useful to know what version of a variable's value is being used at any point in time. To force a re-read of the value of a variable after something has happened, you can use [tf.Variable.read_value](https://tensorflow.google.cn/api_docs/python/tf/Variable#read_value). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.get_variable(\"v\", shape=(), initializer=tf.zeros_initializer())\n",
    "assignment = v.assign_add(1)\n",
    "with tf.control_dependencies([assignment]):\n",
    "    w = v.read_value()  # w is guaranteed to reflect v's value after the\n",
    "                                   # assign_add operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing variables\n",
    "TensorFlow supports two ways of sharing variables:\n",
    "\n",
    "- Explicitly passing [tf.Variable](https://tensorflow.google.cn/api_docs/python/tf/Variable) objects around.\n",
    "- Implicitly wrapping [tf.Variable](https://tensorflow.google.cn/api_docs/python/tf/Variable) objects within [tf.variable_scope](https://tensorflow.google.cn/api_docs/python/tf/variable_scope) objects.\n",
    "\n",
    "While code which explicitly passes variables around is very clear, it is sometimes convenient to write TensorFlow functions that implicitly use variables in their implementations. Most of the functional layers from tf.layer use this approach, as well as all [tf.metrics](https://tensorflow.google.cn/api_docs/python/tf/metrics), and a few other library utilities.\n",
    "\n",
    "Variable scopes allow you to control variable reuse when calling functions which implicitly create and use variables. They also allow you to name your variables in a hierarchical and understandable way.\n",
    "\n",
    "For example, let's say we write a function to create a convolutional / relu layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    # Create variable named \"weights\".\n",
    "    weights = tf.get_variable(\"weight\", kernel_shape,\n",
    "                                 initializer=tf.random_normal_initializer())\n",
    "    # Create variable named \"biases\".\n",
    "    biases = tf.get_variable(\"biases\", bias_shape,\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights,\n",
    "                       strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses short names weights and biases, which is good for clarity. In a real model, however, we want many such convolutional layers, and calling this function repeatedly would not work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable weight already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-c7ae41fba98c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# This fails.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-627d263b5f70>\u001b[0m in \u001b[0;36mconv_relu\u001b[1;34m(input, kernel_shape, bias_shape)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Create variable named \"weights\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     weights = tf.get_variable(\"weight\", kernel_shape,\n\u001b[1;32m----> 4\u001b[1;33m                                  initializer=tf.random_normal_initializer())\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Create variable named \"biases\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     biases = tf.get_variable(\"biases\", bias_shape,\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1315\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m       constraint=constraint)\n\u001b[0m\u001b[0;32m   1318\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1319\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1077\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    731\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 733\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    734\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable weight already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.random_normal([1,10,10,32])\n",
    "input2 = tf.random_normal([1,20,20,32])\n",
    "x = conv_relu(input1, kernel_shape=[5, 5, 32, 32], bias_shape=[32])\n",
    "x = conv_relu(x, kernel_shape=[5, 5, 32, 32], bias_shape = [32])  # This fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the desired behavior is unclear (create new variables or reuse the existing ones?) TensorFlow will fail. Calling conv_relu in different scopes, however, clarifies that we want to create new variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_image_filter(input_images):\n",
    "        with tf.variable_scope(\"conv1\"):\n",
    "            # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "            relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])\n",
    "        with tf.variable_scope(\"conv2\"):\n",
    "            # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n",
    "            return conv_relu(relu1, [5, 5, 32, 32], [32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do want the variables to be shared, you have two options. First, you can create a scope with the same name using reuse=True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"model\"):\n",
    "    output1 = my_image_filter(input1)\n",
    "with tf.variable_scope(\"model\", reuse=True):\n",
    "    output2 = my_image_filter(input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also call scope.reuse_variables() to trigger a reuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"model\") as scope:\n",
    "    output1 = my_image_filter(input1)\n",
    "    scope.reuse_variables()\n",
    "    output2 = my_image_filter(input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since depending on exact string names of scopes can feel dangerous, it's also possible to initialize a variable scope based on another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"model\") as scope:\n",
    "    output1 = my_image_filter(input1)\n",
    "with tf.variable_scope(scope, reuse=True):\n",
    "    output2 = my_image_filter(input2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
